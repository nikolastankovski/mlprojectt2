{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ingredient matching from product photo using OCR \n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from unidecode import unidecode\n",
        "import re\n",
        "import string\n",
        "\n",
        "from nltk.metrics import jaccard_distance\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import easyocr\n",
        "import pytesseract\n",
        "\n",
        "from PIL import Image\n",
        "import subprocess\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reading the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "ingredients = pd.read_excel('../Data/ingredients.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adding new rows for most common misspellings\n",
        "def create_new_rows(generic_name, synonym_values):\n",
        "    # Find the ingredientID based on the generic_name\n",
        "    ingredient_id = ingredients.loc[ingredients['generic_name'] == generic_name, 'ingredientID'].iloc[0]\n",
        "\n",
        "    # Create new rows with the found ingredientID\n",
        "    new_rows = {'ingredientID': [ingredient_id] * len(synonym_values),\n",
        "                'generic_name': [generic_name] * len(synonym_values),\n",
        "                'synonym': synonym_values}\n",
        "    return new_rows\n",
        "\n",
        "new_rows1 = create_new_rows('Alcohol Denat.', ['alchol dent', 'alcoholdenat', 'alcoholdent', 'alchol', 'alkohol'])\n",
        "new_rows2 = create_new_rows('Alpha-Isomethyl Ionone', ['alpha, isomethyl ionon', 'alpha, isomethyl ionone', 'alpha isomethyl ionone', 'alpha,isomethyl ionon', 'alpha-isomethylionone'])\n",
        "new_rows3 = create_new_rows('Dimethicone', ['dimthicone'])\n",
        "new_rows4 = create_new_rows('Linalool', ['linalol'])\n",
        "\n",
        "new_rows_list = [new_rows1, new_rows2, new_rows3, new_rows4]\n",
        "for new_rows in new_rows_list:\n",
        "    ingredients = pd.concat([ingredients, pd.DataFrame(new_rows)], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "synonyms = ingredients['synonym'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "extracted_dir = '../Data/pictures'\n",
        "os.makedirs(extracted_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EasyOCR reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Files conversion\n",
        "files = [f for f in os.listdir(extracted_dir) if f.endswith('.heic') or f.endswith('.heif')]\n",
        "\n",
        "for filename in files:\n",
        "    heic_path = os.path.join(extracted_dir, filename)\n",
        "    jpeg_path = os.path.join(extracted_dir, os.path.splitext(filename)[0] + '.jpg')\n",
        "\n",
        "    subprocess.run(['convert', heic_path, jpeg_path])\n",
        "\n",
        "    os.remove(heic_path)\n",
        "\n",
        "    print(f\"Converted {filename} to {os.path.basename(jpeg_path)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        }
      ],
      "source": [
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "results = []\n",
        "\n",
        "for filename in os.listdir(extracted_dir):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg') or filename.endswith('.webp'):\n",
        "        image_path = os.path.join(extracted_dir, filename)\n",
        "\n",
        "        try:\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is not None:\n",
        "                result = reader.readtext(image, detail=0)\n",
        "                results.append({'filename': filename, 'text': result})\n",
        "            else:\n",
        "                print(f\"Failed to load image: {image_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {str(e)}\")\n",
        "\n",
        "df_pictures = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleaning functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function for unicode transliteration and lower case for ingredient_list\n",
        "def clean_text(s):               \n",
        "    if isinstance(s, str):\n",
        "        s = unidecode(s)    \n",
        "        s = s.lower()\n",
        "        return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom function for text cleaning\n",
        "def clean_text_before_ingredients(lst):\n",
        "    cleaned_list = []\n",
        "    found_ingredients = False\n",
        "\n",
        "    for item in lst:\n",
        "        if isinstance(item, str):\n",
        "            if not found_ingredients and \"ingredients\" in item.lower():\n",
        "                found_ingredients = True\n",
        "                start_index = item.lower().find(\"ingredients\")\n",
        "                end_index = item.find(\":\", start_index)\n",
        "                if start_index != -1 and end_index != -1:\n",
        "                    cleaned_item = item[end_index + 1:].lstrip()\n",
        "                    cleaned_list.append(unidecode(cleaned_item))\n",
        "            elif found_ingredients:\n",
        "                # Check for '.' and stop processing the list\n",
        "                dot_index = item.find('.')\n",
        "                if dot_index != -1:\n",
        "                    cleaned_item = item[:dot_index].lstrip()\n",
        "                    cleaned_list.append(unidecode(cleaned_item))\n",
        "                    break\n",
        "                else:\n",
        "                    cleaned_list.append(unidecode(item))\n",
        "        else:\n",
        "            cleaned_list.append(None)  # Remove the entire list\n",
        "\n",
        "    return [item for item in cleaned_list if item is not None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove unclosed brackets\n",
        "def remove_unclosed_brackets(input_str):\n",
        "    if input_str is None or not isinstance(input_str, str):\n",
        "        return input_str\n",
        "\n",
        "    stack = []\n",
        "    result = list(input_str)\n",
        "\n",
        "    for i, char in enumerate(input_str):\n",
        "        if char in ['(', '[']:\n",
        "            stack.append(i)\n",
        "        elif char in [')', ']']:\n",
        "            if stack:\n",
        "                stack.pop()\n",
        "            else:\n",
        "                result[i] = ' '\n",
        "\n",
        "    # Replace unclosed open brackets with an empty space\n",
        "    for index in stack:\n",
        "        result[index] = ' '\n",
        "\n",
        "    return ''.join(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preform cleaning after feading the files with EasyOCR reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def perform_first_ocr_cleaning(products):\n",
        "    \n",
        "    products['full_ingredient_list'] = products['text_from_ocr'].apply(lambda x: ' '.join(map(str, x)))\n",
        "    products['ingredient_list'] = products['full_ingredient_list']\n",
        "    products['ingredient_list'] = products['ingredient_list'].apply(clean_text)\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.split(r',|;|\\|')\n",
        "    products.reset_index(drop=True, inplace=True)\n",
        "    products['ingredient_list'] = products['ingredient_list'].apply(clean_text_before_ingredients)\n",
        "    products = products.explode('ingredient_list')\n",
        "    products['ingredient_list'] = products['ingredient_list'].apply(remove_unclosed_brackets)\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace('[', '(').str.replace(']', ')')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace('\\\\', '/')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.lstrip(',')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace(' ,', ', ')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.lstrip('/')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.rstrip(string.punctuation.replace(')', ''))\n",
        "    \n",
        "    special_characters = ['*', '$', '?', '!', '@', '}', '{', '--', '>', '<', '~', '&', '=', '\"']\n",
        "    for char in special_characters:\n",
        "        products['ingredient_list'] = products['ingredient_list'].astype(str).str.replace(char, ' ')\n",
        "\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace(r'cl (\\d{5})', r'ci \\1')              # zamena na cl XXXXX so ci XXXXX    \n",
        "    products['ingredient_list'] = products['ingredient_list'].replace(r',+', ',', regex=True)\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.strip().str.replace(r'\\s+', ' ')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\s*/\\s*', '/')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\s*-\\s*', '-')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\s+\\.', '.')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\(\\s*', '(').str.replace(r'\\s*\\)', ')')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace('f,i,l,', 'fil')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.strip()\n",
        "    products = products[~products['ingredient_list'].astype(str).str.match(r'^[\\d\\W]+$')]\n",
        "    products = products[~products['ingredient_list'].str.strip(string.punctuation).eq('')]\n",
        "    products = products[~products['ingredient_list'].apply(lambda x: pd.to_numeric(x, errors='coerce')).notna() | (products['ingredient_list'] == '')]\n",
        "    products = products[~products['ingredient_list'].str.len() < 3]   \n",
        "    products['ingredient_list'] = products['ingredient_list'].str.strip()   \n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\s+', ' ', regex=True)                      # Brisenje na prazni stringovi i NaN\n",
        "    products.dropna(subset=['ingredient_list'], inplace=True)\n",
        "    products.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "    return products\n",
        "\n",
        "products1 = df_pictures.copy()\n",
        "products1.rename(columns={'text': 'text_from_ocr'}, inplace=True)\n",
        "products1.rename(columns={'filename': 'product_name'}, inplace=True)\n",
        "\n",
        "products_cleaned_first_ocr = perform_first_ocr_cleaning(products1)                                                      # Call the function to perform the cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tesseract OCR reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "filtered_products = products_cleaned_first_ocr[\n",
        "    (products_cleaned_first_ocr['ingredient_list'].str.len() > 100)      # Gi zemame redovite so dolgi stringovi koi prviot algoritam ne gi separira               \n",
        "]\n",
        "\n",
        "# Check if there are any products that meet the condition\n",
        "if not filtered_products.empty:\n",
        "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for filename in os.listdir(extracted_dir):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg') or filename.endswith('.webp'):\n",
        "            image_path = os.path.join(extracted_dir, filename)\n",
        "\n",
        "            try:\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is not None:\n",
        "                    # Use pytesseract.image_to_string to extract text\n",
        "                    result = pytesseract.image_to_string(image)\n",
        "                    results.append({'filename': filename, 'text': result})\n",
        "                else:\n",
        "                    print(f\"Failed to load image: {image_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {filename}: {str(e)}\")\n",
        "\n",
        "    # Create a DataFrame from the OCR results\n",
        "    df_pictures_tesseract = pd.DataFrame(results)\n",
        "    \n",
        "    # Merge the OCR results with the filtered_products DataFrame\n",
        "    df_pictures_tesseract = pd.merge(filtered_products, df_pictures_tesseract, how='inner', left_on='product_name', right_on='filename')\n",
        "else:\n",
        "    # If there are no products that meet the condition, create an empty DataFrame\n",
        "    df_pictures_tesseract = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preform cleaning after feading the files with Tesseract OCR reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def perform_second_ocr_cleaning(products):\n",
        "\n",
        "        products['full_ingredient_list'] = products['text_from_ocr']\n",
        "        products['full_ingredient_list'] = products['full_ingredient_list'].apply(lambda x: x.split('\\n'))          # Split each paragraph into a list\n",
        "        products['full_ingredient_list'] = products['full_ingredient_list'].apply(lambda x: [paragraph.strip() for paragraph in x if paragraph.strip()])    # Remove empty paragraphs if any\n",
        "        products['full_ingredient_list'] = products['full_ingredient_list'].apply(lambda x: ' '.join(map(str, x)))\n",
        "        products['ingredient_list'] = products['full_ingredient_list']                                              # Making unicode transliteration, lower case and tokenization\n",
        "\n",
        "        split_characters = [',', '|', '*', '«', '»', '-', ':', '+']        \n",
        "        for char in split_characters:\n",
        "            products['ingredient_list'] = products['ingredient_list'].apply(lambda x: ', '.join(x.split(char)))     # Iterate over each split character and perform the split [',', '|', '*', '«', '»', '-', ':', '+'] \n",
        "        products.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        products['ingredient_list'] = products['ingredient_list'].apply(clean_text)\n",
        "        products['ingredient_list'] = products['ingredient_list'].apply(lambda x: x.split(','))\n",
        "        products['ingredient_list'] = products['ingredient_list'].tolist()        \n",
        "        products['ingredient_list'] = products['ingredient_list'].apply(clean_text_before_ingredients)              # Apply the cleaning function\n",
        "        products = products.explode('ingredient_list')        \n",
        "        products['ingredient_list'] = products['ingredient_list'].apply(remove_unclosed_brackets)\n",
        "        products['ingredient_list'] = products['ingredient_list'].astype(str)\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace('[', '(').str.replace(']', ')')       # zamena na aglesti zagradi so obicni\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace('\\\\', '/')                            # zamena na \\ so /\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.lstrip(',')                                   # brisenje na ',' ako stringot pocnuva so ','\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace(' ,', ', ')                           # zamena na ' ,' so ', '\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.lstrip('/')                                   # brisenje / na pocetok na string\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.rstrip(string.punctuation.replace(')', ''))   # brisenje punktuacija na kraj na sting, no bez zagradite\n",
        "\n",
        "        special_characters = ['*', '$', '?', '!', '@', '}', '{', '--', '>', '<', '~', '&', '=', '\"']\n",
        "        for char in special_characters:\n",
        "            products['ingredient_list'] = products['ingredient_list'].astype(str).str.replace(char, ' ')            # brisenje na specijalnite znaci bilo kade vo stringot\n",
        "        \n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace(r'cl (\\d{5})', r'ci \\1')              # zamena na cl XXXXX so ci XXXXX\n",
        "        products['ingredient_list'] = products['ingredient_list'].replace(r',+', ',', regex=True)                   # brisenje na povekje od 1 posledovatelni zapirki\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.strip().str.replace(r'\\s+', ' ')              # brisenje na povekje od 1 posledovatelni prazni mesta\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\s*/\\s*', '/')                      # brisenje na prazni mesta pred i posle '/'\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\s*-\\s*', '-')                      # brisenje na prazni mesta pred i posle '-'\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\s+\\.', '.')                        # brisenje na prazno mesto pred '.'\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\(\\s*', '(').str.replace(r'\\s*\\)', ')') # brisenje na prazni mesta posle otvorena zagrada i pred zatvorena zagrada\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace('f,i,l,', 'fil')\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.strip()                                       # trim\n",
        "        products = products[~products['ingredient_list'].astype(str).str.match(r'^[\\d\\W]+$')]                       # brisenje na red koj sodrzi samo broj i punktuacija\n",
        "        products = products[~products['ingredient_list'].str.strip(string.punctuation).eq('')]                      # brisenje na red koj sodrzi samo punktuacija\n",
        "        products = products[~products['ingredient_list'].apply(lambda x: pd.to_numeric(x, errors='coerce')).notna() | (products['ingredient_list'] == '')]  # samo broj\n",
        "        mask_to_drop = (products['ingredient_list'].str.len() < 3) | (products['ingredient_list'].str.len() > 80)   # Brisenje na red koj sodrzi pomalku od 3 ili povekje od 70 karakteri \n",
        "        products = products[~mask_to_drop]\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.strip()   \n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\s+', ' ', regex=True)              # Brisenje na prazni stringovi i NaN\n",
        "        products.dropna(subset=['ingredient_list'], inplace=True)\n",
        "        products.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        return products\n",
        "\n",
        "\n",
        "products2 = df_pictures_tesseract.copy()\n",
        "columns_to_drop = ['product_name', 'text_from_ocr', 'full_ingredient_list', 'ingredient_list']                      # Columns to drop from first ocr read\n",
        "products2.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
        "products2.rename(columns={'text': 'text_from_ocr'}, inplace=True)                                                   # Renaming the columns \n",
        "products2.rename(columns={'filename': 'product_name'}, inplace=True)\n",
        "\n",
        "products_cleaned_second_ocr = perform_second_ocr_cleaning(products2)                                                # Call the function to perform the cleaning   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_name</th>\n",
              "      <th>text_from_ocr</th>\n",
              "      <th>full_ingredient_list</th>\n",
              "      <th>ingredient_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>1000092570.jpg</td>\n",
              "      <td>[INGREDIENTS, AqeWater) Squalane; Caprvlic/Cap...</td>\n",
              "      <td>INGREDIENTS AqeWater) Squalane; Caprvlic/Capri...</td>\n",
              "      <td>benzyl alco-giucosaminen citric aoic srbitotor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>20231204_141323.jpg</td>\n",
              "      <td>[PCOoc|, lontano dalla luce diretta del sole: ...</td>\n",
              "      <td>PCOoc| lontano dalla luce diretta del sole: In...</td>\n",
              "      <td>alcohol methorvoieenzorimethare ethvlhexy sali...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>20231204_141323.jpg</td>\n",
              "      <td>[PCOoc|, lontano dalla luce diretta del sole: ...</td>\n",
              "      <td>PCOoc| lontano dalla luce diretta del sole: In...</td>\n",
              "      <td>coperica gertenaheen phenvlbenzimidazole sullo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>20231204_142537.jpg</td>\n",
              "      <td>[2, ne:, 17, 3 =, na y, 1, 1, 1, 0, %t, 6, 0, ...</td>\n",
              "      <td>2 ne: 17 3 = na y 1 1 1 0 %t 6 0 G; rater 2 Z7...</td>\n",
              "      <td>potassiomurorbaleride goramidrort hydroxde tor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>20231204_142537.jpg</td>\n",
              "      <td>[2, ne:, 17, 3 =, na y, 1, 1, 1, 0, %t, 6, 0, ...</td>\n",
              "      <td>2 ne: 17 3 = na y 1 1 1 0 %t 6 0 G; rater 2 Z7...</td>\n",
              "      <td>corinedefarme com used the end of : la4 pa0420...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1719</th>\n",
              "      <td>IMG_6968.jpg</td>\n",
              "      <td>[3258484750, L1S, Mirrobiom schutz FORMEL, FOR...</td>\n",
              "      <td>3258484750 L1S Mirrobiom schutz FORMEL FORMULe...</td>\n",
              "      <td>eur 42090 anti-schuppen shampoo gchtbare schup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1720</th>\n",
              "      <td>IMG_6968.jpg</td>\n",
              "      <td>[3258484750, L1S, Mirrobiom schutz FORMEL, FOR...</td>\n",
              "      <td>3258484750 L1S Mirrobiom schutz FORMEL FORMULe...</td>\n",
              "      <td>%s wvoyznts et desadditk atculs peg bases sur ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1721</th>\n",
              "      <td>IMG_6968.jpg</td>\n",
              "      <td>[3258484750, L1S, Mirrobiom schutz FORMEL, FOR...</td>\n",
              "      <td>3258484750 L1S Mirrobiom schutz FORMEL FORMULe...</td>\n",
              "      <td>fgey %oxgneusement avec de keau: awverienze: e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1722</th>\n",
              "      <td>IMG_6968.jpg</td>\n",
              "      <td>[3258484750, L1S, Mirrobiom schutz FORMEL, FOR...</td>\n",
              "      <td>3258484750 L1S Mirrobiom schutz FORMEL FORMULe...</td>\n",
              "      <td>scizcquare abbondantemente con acqua hodtet lg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1747</th>\n",
              "      <td>IMG_6972.jpg</td>\n",
              "      <td>[MARKENQUALITAT, Wirkung, Peleoe, Die FESTE SP...</td>\n",
              "      <td>MARKENQUALITAT Wirkung Peleoe Die FESTE SPULUM...</td>\n",
              "      <td>ci 77891 hergestellt fur dirk rossmann gmbh he...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             product_name                                      text_from_ocr  \\\n",
              "139        1000092570.jpg  [INGREDIENTS, AqeWater) Squalane; Caprvlic/Cap...   \n",
              "172   20231204_141323.jpg  [PCOoc|, lontano dalla luce diretta del sole: ...   \n",
              "173   20231204_141323.jpg  [PCOoc|, lontano dalla luce diretta del sole: ...   \n",
              "218   20231204_142537.jpg  [2, ne:, 17, 3 =, na y, 1, 1, 1, 0, %t, 6, 0, ...   \n",
              "220   20231204_142537.jpg  [2, ne:, 17, 3 =, na y, 1, 1, 1, 0, %t, 6, 0, ...   \n",
              "...                   ...                                                ...   \n",
              "1719         IMG_6968.jpg  [3258484750, L1S, Mirrobiom schutz FORMEL, FOR...   \n",
              "1720         IMG_6968.jpg  [3258484750, L1S, Mirrobiom schutz FORMEL, FOR...   \n",
              "1721         IMG_6968.jpg  [3258484750, L1S, Mirrobiom schutz FORMEL, FOR...   \n",
              "1722         IMG_6968.jpg  [3258484750, L1S, Mirrobiom schutz FORMEL, FOR...   \n",
              "1747         IMG_6972.jpg  [MARKENQUALITAT, Wirkung, Peleoe, Die FESTE SP...   \n",
              "\n",
              "                                   full_ingredient_list  \\\n",
              "139   INGREDIENTS AqeWater) Squalane; Caprvlic/Capri...   \n",
              "172   PCOoc| lontano dalla luce diretta del sole: In...   \n",
              "173   PCOoc| lontano dalla luce diretta del sole: In...   \n",
              "218   2 ne: 17 3 = na y 1 1 1 0 %t 6 0 G; rater 2 Z7...   \n",
              "220   2 ne: 17 3 = na y 1 1 1 0 %t 6 0 G; rater 2 Z7...   \n",
              "...                                                 ...   \n",
              "1719  3258484750 L1S Mirrobiom schutz FORMEL FORMULe...   \n",
              "1720  3258484750 L1S Mirrobiom schutz FORMEL FORMULe...   \n",
              "1721  3258484750 L1S Mirrobiom schutz FORMEL FORMULe...   \n",
              "1722  3258484750 L1S Mirrobiom schutz FORMEL FORMULe...   \n",
              "1747  MARKENQUALITAT Wirkung Peleoe Die FESTE SPULUM...   \n",
              "\n",
              "                                        ingredient_list  \n",
              "139   benzyl alco-giucosaminen citric aoic srbitotor...  \n",
              "172   alcohol methorvoieenzorimethare ethvlhexy sali...  \n",
              "173   coperica gertenaheen phenvlbenzimidazole sullo...  \n",
              "218   potassiomurorbaleride goramidrort hydroxde tor...  \n",
              "220   corinedefarme com used the end of : la4 pa0420...  \n",
              "...                                                 ...  \n",
              "1719  eur 42090 anti-schuppen shampoo gchtbare schup...  \n",
              "1720  %s wvoyznts et desadditk atculs peg bases sur ...  \n",
              "1721  fgey %oxgneusement avec de keau: awverienze: e...  \n",
              "1722  scizcquare abbondantemente con acqua hodtet lg...  \n",
              "1747  ci 77891 hergestellt fur dirk rossmann gmbh he...  \n",
              "\n",
              "[61 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "mask_to_drop = products_cleaned_first_ocr['ingredient_list'].str.len() > 100                                         # Brisenje na redovite koi sodrzat povekje od 80 karakteri\n",
        "rows_to_drop = products_cleaned_first_ocr[mask_to_drop]\n",
        "display(rows_to_drop)\n",
        "products_to_drop = products_cleaned_first_ocr.loc[mask_to_drop, 'product_name'].unique()                            # Identify the product names for which the condition is met\n",
        "products_cleaned_first_ocr = products_cleaned_first_ocr[~products_cleaned_first_ocr['product_name'].isin(products_to_drop)] # Brisenje na recordite od products_cleaned_first_ocr, bidejki se vcituvaat od drugata biblioteka\n",
        "products_cleaned_first_ocr.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_to_drop2 = products_cleaned_second_ocr['ingredient_list'].str.len() > 70                                         # Brisenje na redovite koi sodrzat povekje od 70 karakteri vo imeto na sostojkite\n",
        "rows_to_drop2 = products_cleaned_second_ocr[mask_to_drop]\n",
        "display(rows_to_drop2)\n",
        "products_to_drop2 = products_cleaned_second_ocr.loc[mask_to_drop2, 'product_name'].unique()                            # Identify the product names for which the condition is met\n",
        "products_cleaned_second_ocr = products_cleaned_second_ocr[~products_cleaned_second_ocr['product_name'].isin(products_to_drop2)] # Brisenje na recordite od products_cleaned_first_ocr, bidejki se vcituvaat od drugata biblioteka\n",
        "products_cleaned_second_ocr.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Concatanating dataframes from both readers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "products = pd.concat([products_cleaned_first_ocr, products_cleaned_second_ocr], axis=0)                             # Concatenate the two DataFrames along the columns\n",
        "products = products.sort_values(by='product_name')\n",
        "\n",
        "products['text_from_ocr'] = products['text_from_ocr'].apply(tuple)                                                  # Brisenje duplikati\n",
        "products.drop_duplicates(inplace=True)\n",
        "products.reset_index(drop=True, inplace=True)\n",
        "\n",
        "products['productID'] = products.groupby('product_name').ngroup()                                                   # Dodavanje index colona za sekoj proizvod\n",
        "products.insert(0, 'productID', products.pop('productID'))                                                          # Move 'productID' as first column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "products_cleaned_first_ocr.to_excel('first_ocr.xlsx')\n",
        "products_cleaned_second_ocr.to_excel('second_ocr.xlsx')\n",
        "products.to_excel('ocr.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>productID</th>\n",
              "      <th>product_name</th>\n",
              "      <th>text_from_ocr</th>\n",
              "      <th>full_ingredient_list</th>\n",
              "      <th>ingredient_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [productID, product_name, text_from_ocr, full_ingredient_list, ingredient_list]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "duplicates_to_remove = products[products.duplicated()]                          # Filtriranje na dupli redovi\n",
        "display(duplicates_to_remove)\n",
        "\n",
        "products.drop_duplicates(inplace=True)                                          # Brisenje na dupli redovi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>productID</th>\n",
              "      <th>product_name</th>\n",
              "      <th>text_from_ocr</th>\n",
              "      <th>full_ingredient_list</th>\n",
              "      <th>ingredient_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [productID, product_name, text_from_ocr, full_ingredient_list, ingredient_list]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rows_with_string_nan = products[products['ingredient_list'].eq('nan')]          # Filtriranje na redovi so string nan\n",
        "display(rows_with_string_nan)\n",
        "\n",
        "products = products[~products['ingredient_list'].eq('nan')]                     # Brisenje na redovi so string nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>productID</th>\n",
              "      <th>product_name</th>\n",
              "      <th>text_from_ocr</th>\n",
              "      <th>full_ingredient_list</th>\n",
              "      <th>ingredient_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [productID, product_name, text_from_ocr, full_ingredient_list, ingredient_list]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rows_with_NaN = products[~products['ingredient_list'].notna()]                  # Filtriranje na redovi so NaN\n",
        "display(rows_with_NaN)\n",
        "products = products[products['ingredient_list'].notna()]                        # Brisenje na redovi so NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "products.to_excel('ingredient_list_for_matching.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Converting to list\n",
        "ingredient_names = products['ingredient_list'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Jaccard distance Matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_first_match(ingredient, candidates, threshold=0.50):\n",
        "    ingredient_set = set(re.split(r'\\W+', ingredient))\n",
        "\n",
        "    # Set to keep track of matched ingredients\n",
        "    matched_ingredients = set()\n",
        "\n",
        "    for candidate in candidates:\n",
        "        # Skip if candidate ingredient has already been matched\n",
        "        if pd.notna(candidate):  # Check if candidate is not NaN\n",
        "            if candidate in matched_ingredients:\n",
        "                continue\n",
        "\n",
        "            if isinstance(candidate, str):  # Check if candidate is a string\n",
        "                candidate_set = set(re.split(r'\\W+', candidate))\n",
        "                union_size = len(ingredient_set.union(candidate_set))\n",
        "\n",
        "                if union_size != 0:\n",
        "                    distance = jaccard_distance(ingredient_set, candidate_set)\n",
        "                    similarity = 1 - distance\n",
        "\n",
        "                    if similarity > threshold:\n",
        "                        # Add the matched ingredient to the set\n",
        "                        matched_ingredients.add(candidate)\n",
        "                        \n",
        "                        # Return the first match and exit the function\n",
        "                        return candidate\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "matches_df = pd.DataFrame(columns=['Matching Ingredient', 'Synonym'])\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for ingredient in ingredient_names:\n",
        "    if isinstance(ingredient, str):\n",
        "        direct_match = [synonym for synonym in synonyms if synonym == ingredient] or [None]\n",
        "\n",
        "        if direct_match[0] == None:\n",
        "            match = find_first_match(ingredient, synonyms)\n",
        "        else:\n",
        "            match = direct_match[0]\n",
        "\n",
        "        df = pd.DataFrame({'Matching Ingredient': [ingredient], 'Synonym': [match]})\n",
        "\n",
        "        dfs.append(df)\n",
        "\n",
        "matches_df = pd.concat(dfs, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "synonym_to_generic = dict(zip(ingredients['synonym'], ingredients['generic_name']))\n",
        "\n",
        "# Add a new column to matches_df to store the corresponding generic name\n",
        "matches_df['Generic Name'] = None\n",
        "\n",
        "# Loop through each ingredient\n",
        "for index, row in matches_df.iterrows():\n",
        "    ingredient = row['Matching Ingredient']\n",
        "    match = row['Synonym']\n",
        "\n",
        "    # Check if the match is not None\n",
        "    if match is not None:\n",
        "        # Use the dictionary to find the corresponding generic name\n",
        "        generic_name = synonym_to_generic.get(match)\n",
        "\n",
        "        # Update the 'Generic_Name' column in matches_df\n",
        "        matches_df.at[index, 'Generic Name'] = generic_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MATCHED ingredients:               73.74 % \t/ 1536\n",
            "NOT MATCHED ingredients:           26.26 % \t/ 547\n",
            "\n",
            "EXACT MATCH of ingredients:        63.0 %\n",
            "JACCARD DISTANCE MATCH of ing.:    10.74 %\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Matching Ingredient</th>\n",
              "      <th>Synonym</th>\n",
              "      <th>Generic Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aqua water</td>\n",
              "      <td>aqua water</td>\n",
              "      <td>Water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bidens pilosa extract</td>\n",
              "      <td>bidens pilosa extract</td>\n",
              "      <td>Bidens Pilosa Extract</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hditrimethylol hexyllactone crosspolymer butyr...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>withania somnifera root extract</td>\n",
              "      <td>withania somnifera root extract</td>\n",
              "      <td>Withania Somnifera Root Extract</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>helianthus annuus (sunflower) seed oil</td>\n",
              "      <td>helianthus annuus seed</td>\n",
              "      <td>Helianthus Annuus Seed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2078</th>\n",
              "      <td>disodium edta</td>\n",
              "      <td>disodium edta</td>\n",
              "      <td>Disodium EDTA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2079</th>\n",
              "      <td>copper</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2080</th>\n",
              "      <td>hydroxyethylcellulose lauricacid</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2081</th>\n",
              "      <td>laurylalcohol diphosphonic acid</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2082</th>\n",
              "      <td>60 hydrogenated castor ou</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2083 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Matching Ingredient  \\\n",
              "0                                            aqua water   \n",
              "1                                 bidens pilosa extract   \n",
              "2     hditrimethylol hexyllactone crosspolymer butyr...   \n",
              "3                       withania somnifera root extract   \n",
              "4                helianthus annuus (sunflower) seed oil   \n",
              "...                                                 ...   \n",
              "2078                                      disodium edta   \n",
              "2079                                             copper   \n",
              "2080                   hydroxyethylcellulose lauricacid   \n",
              "2081                    laurylalcohol diphosphonic acid   \n",
              "2082                          60 hydrogenated castor ou   \n",
              "\n",
              "                              Synonym                     Generic Name  \n",
              "0                          aqua water                            Water  \n",
              "1               bidens pilosa extract            Bidens Pilosa Extract  \n",
              "2                                None                             None  \n",
              "3     withania somnifera root extract  Withania Somnifera Root Extract  \n",
              "4              helianthus annuus seed           Helianthus Annuus Seed  \n",
              "...                               ...                              ...  \n",
              "2078                    disodium edta                    Disodium EDTA  \n",
              "2079                             None                             None  \n",
              "2080                             None                             None  \n",
              "2081                             None                             None  \n",
              "2082                             None                             None  \n",
              "\n",
              "[2083 rows x 3 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "none_count = 0\n",
        "for value in matches_df['Synonym']:\n",
        "    if str(value).strip().lower() == 'none':\n",
        "        none_count += 1\n",
        "\n",
        "matched = round((len(products) - none_count)/len(products), 4)*100\n",
        "not_matched = round((100-matched), 4)\n",
        "exact_matches = products['ingredient_list'][products['ingredient_list'].isin(ingredients['synonym'].values)].tolist()\n",
        "exact_matches = round(len(exact_matches)/len(products['ingredient_list']), 2)*100\n",
        "\n",
        "print(f'MATCHED ingredients:               {round(matched, 2)} % \\t/ {len(ingredient_names) - none_count}')\n",
        "print(f'NOT MATCHED ingredients:           {not_matched} % \\t/ {none_count}')\n",
        "print()\n",
        "print(f'EXACT MATCH of ingredients:        {exact_matches} %')\n",
        "print(f'JACCARD DISTANCE MATCH of ing.:    {round(matched-exact_matches, 2)} %')\n",
        "\n",
        "matches_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "matches_df[['Generic Name', 'Synonym', 'Matching Ingredient']].to_excel('matches_0.50.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value: peg, Frequency: 8\n",
            "Value: propanediol, Frequency: 8\n",
            "Value: alpha, Frequency: 7\n",
            "Value: betaine, Frequency: 6\n",
            "Value: alpha-isomethyl lonone, Frequency: 5\n",
            "Value: c12, Frequency: 4\n",
            "Value: pentaerythrityl tetra, Frequency: 3\n",
            "Value: coco, Frequency: 3\n",
            "Value: ppg, Frequency: 3\n",
            "Value: glycerides, Frequency: 3\n",
            "Value: ceteareth, Frequency: 3\n",
            "Value: cl 19140, Frequency: 3\n",
            "Value: cl 77492, Frequency: 2\n",
            "Value: aquo, Frequency: 2\n",
            "Value: 1-methylhydan-toin-2-imide, Frequency: 2\n",
            "Value: cetearylalcohol, Frequency: 2\n",
            "Value: tocophery acetate, Frequency: 2\n",
            "Value: glucoside, Frequency: 2\n",
            "Value: caprylic/capric trigly-ceride, Frequency: 2\n",
            "Value: polyglyceryl, Frequency: 2\n",
            "Value: cerin, Frequency: 2\n",
            "Value: cl 14700, Frequency: 2\n",
            "Value: porfum, Frequency: 2\n",
            "Value: lsomethy lonone, Frequency: 2\n",
            "Value: gly, Frequency: 2\n",
            "Value: ethylhexyiglycerin, Frequency: 2\n",
            "Value: cl 77891, Frequency: 2\n",
            "Value: fragra nce, Frequency: 1\n",
            "Value: alcoh ol denat glycerin, Frequency: 1\n",
            "Value: phenoxyetha-nol, Frequency: 1\n"
          ]
        }
      ],
      "source": [
        "# Analysis of unmatched ingredients\n",
        "filtered_df = matches_df[matches_df['Generic Name'].isna()]\n",
        "value_counts = filtered_df['Matching Ingredient'].value_counts()\n",
        "\n",
        "# Print the first 20 most frequent values and their frequencies\n",
        "for value, frequency in value_counts.head(30).iteritems():\n",
        "    print(f\"Value: {value}, Frequency: {frequency}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
