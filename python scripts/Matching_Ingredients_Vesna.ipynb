{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm       \n",
    "import copy\n",
    "import itertools \n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Unsupervised Learning models / Clustering\n",
    "import scipy.spatial.distance as ssd\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Unsupervised Learning models / Clustering metrics\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# NLP\n",
    "import tensorflow as tf\n",
    "import nltk \n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer # BoW, TFIDF\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer, PunktSentenceTokenizer\n",
    "from keras.preprocessing.text import Tokenizer # Ovoj Tokenizer gi pretvara direktno vo unikatni broevi\n",
    "from keras.utils import pad_sequences\n",
    "eng_stopwords = stopwords.words(\"english\")\n",
    "import gensim.downloader as gen_downloader\n",
    "\n",
    "from scipy.spatial.distance import cosine # cosine similarity\n",
    "from unidecode import unidecode           # returns unicode characters (unicode transliteration)\n",
    "\n",
    "#from keras.utils import np_utils         # one hot encoding vo VS Code\n",
    "from keras.utils import to_categorical    # one hot encoding vo Colab\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "random.seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# MATCHING THE INGREDIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
