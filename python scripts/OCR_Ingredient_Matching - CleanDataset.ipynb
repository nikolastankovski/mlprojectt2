{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ingredient matching from product photo using OCR \n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from unidecode import unidecode\n",
        "import re\n",
        "import string\n",
        "\n",
        "from nltk.metrics import jaccard_distance\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import easyocr\n",
        "import pytesseract\n",
        "\n",
        "from PIL import Image\n",
        "import subprocess\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reading the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "ingredients = pd.read_csv('../Data/ingredients.csv')\n",
        "synonyms = ingredients['synonym'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "extracted_dir = '../Data/Pictures_Vesna_Tamara - Clean'\n",
        "os.makedirs(extracted_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EasyOCR reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Files conversion\n",
        "files = [f for f in os.listdir(extracted_dir) if f.endswith('.heic') or f.endswith('.heif')]\n",
        "\n",
        "for filename in files:\n",
        "    heic_path = os.path.join(extracted_dir, filename)\n",
        "    jpeg_path = os.path.join(extracted_dir, os.path.splitext(filename)[0] + '.jpg')\n",
        "\n",
        "    subprocess.run(['convert', heic_path, jpeg_path])\n",
        "\n",
        "    os.remove(heic_path)\n",
        "\n",
        "    print(f\"Converted {filename} to {os.path.basename(jpeg_path)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        }
      ],
      "source": [
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "results = []\n",
        "\n",
        "for filename in os.listdir(extracted_dir):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg') or filename.endswith('.webp'):\n",
        "        image_path = os.path.join(extracted_dir, filename)\n",
        "\n",
        "        try:\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is not None:\n",
        "                result = reader.readtext(image, detail=0)\n",
        "                results.append({'filename': filename, 'text': result})\n",
        "            else:\n",
        "                print(f\"Failed to load image: {image_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {str(e)}\")\n",
        "\n",
        "df_pictures = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleaning functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function for unicode transliteration and lower case for ingredient_list\n",
        "def clean_text(s):               \n",
        "    if isinstance(s, str):\n",
        "        s = unidecode(s)    \n",
        "        s = s.lower()\n",
        "        return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom function for text cleaning\n",
        "def clean_text_before_ingredients(lst):\n",
        "    cleaned_list = []\n",
        "    found_ingredients = False\n",
        "\n",
        "    for item in lst:\n",
        "        if isinstance(item, str):\n",
        "            if not found_ingredients and \"ingredients\" in item.lower():\n",
        "                found_ingredients = True\n",
        "                start_index = item.lower().find(\"ingredients\")\n",
        "                end_index = item.find(\":\", start_index)\n",
        "                if start_index != -1 and end_index != -1:\n",
        "                    cleaned_item = item[end_index + 1:].lstrip()\n",
        "                    cleaned_list.append(unidecode(cleaned_item))\n",
        "            elif found_ingredients:\n",
        "                # Check for '.' and stop processing the list\n",
        "                dot_index = item.find('.')\n",
        "                if dot_index != -1:\n",
        "                    cleaned_item = item[:dot_index].lstrip()\n",
        "                    cleaned_list.append(unidecode(cleaned_item))\n",
        "                    break\n",
        "                else:\n",
        "                    cleaned_list.append(unidecode(item))\n",
        "        else:\n",
        "            cleaned_list.append(None)  # Remove the entire list\n",
        "\n",
        "    return [item for item in cleaned_list if item is not None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove unclosed brackets\n",
        "def remove_unclosed_brackets(input_str):\n",
        "    if input_str is None or not isinstance(input_str, str):\n",
        "        return input_str\n",
        "\n",
        "    stack = []\n",
        "    result = list(input_str)\n",
        "\n",
        "    for i, char in enumerate(input_str):\n",
        "        if char in ['(', '[']:\n",
        "            stack.append(i)\n",
        "        elif char in [')', ']']:\n",
        "            if stack:\n",
        "                stack.pop()\n",
        "            else:\n",
        "                result[i] = ' '\n",
        "\n",
        "    # Replace unclosed open brackets with an empty space\n",
        "    for index in stack:\n",
        "        result[index] = ' '\n",
        "\n",
        "    return ''.join(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preform cleaning after feading the files with EasyOCR reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def perform_first_ocr_cleaning(products):\n",
        "    \n",
        "    products['full_ingredient_list'] = products['text_from_ocr'].apply(lambda x: ' '.join(map(str, x)))\n",
        "    products['ingredient_list'] = products['full_ingredient_list']\n",
        "    products['ingredient_list'] = products['ingredient_list'].apply(clean_text)\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.split(r',|;|\\|')\n",
        "    products.reset_index(drop=True, inplace=True)\n",
        "    products['ingredient_list'] = products['ingredient_list'].apply(clean_text_before_ingredients)\n",
        "    products = products.explode('ingredient_list')\n",
        "    products['ingredient_list'] = products['ingredient_list'].apply(remove_unclosed_brackets)\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace('[', '(').str.replace(']', ')')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace('\\\\', '/')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.lstrip(',')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace(' ,', ', ')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.lstrip('/')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.rstrip(string.punctuation.replace(')', ''))\n",
        "    \n",
        "    special_characters = ['*', '$', '?', '!', '@', '}', '{', '_', '--', '>', '<', '~', '&', '=', '\"']\n",
        "    for char in special_characters:\n",
        "        products['ingredient_list'] = products['ingredient_list'].astype(str).str.replace(char, ' ')\n",
        "        \n",
        "    products['ingredient_list'] = products['ingredient_list'].replace(r',+', ',', regex=True)\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.strip().str.replace(r'\\s+', ' ')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\s*/\\s*', '/')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\s*-\\s*', '-')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\s+\\.', '.')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\(\\s*', '(').str.replace(r'\\s*\\)', ')')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace('f,i,l,', 'fil')\n",
        "    products['ingredient_list'] = products['ingredient_list'].str.strip()\n",
        "    products = products[~products['ingredient_list'].astype(str).str.match(r'^[\\d\\W]+$')]\n",
        "    products = products[~products['ingredient_list'].str.strip(string.punctuation).eq('')]\n",
        "    products = products[~products['ingredient_list'].apply(lambda x: pd.to_numeric(x, errors='coerce')).notna() | (products['ingredient_list'] == '')]\n",
        "    products = products[~products['ingredient_list'].str.len() < 3]   \n",
        "    products['ingredient_list'] = products['ingredient_list'].str.strip()   \n",
        "    products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\s+', ' ', regex=True)                      # Brisenje na prazni stringovi i NaN\n",
        "    products.dropna(subset=['ingredient_list'], inplace=True)\n",
        "    products.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "    return products\n",
        "\n",
        "products1 = df_pictures.copy()\n",
        "products1.rename(columns={'text': 'text_from_ocr'}, inplace=True)\n",
        "products1.rename(columns={'filename': 'product_name'}, inplace=True)\n",
        "\n",
        "products_cleaned_first_ocr = perform_first_ocr_cleaning(products1)                                                      # Call the function to perform the cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tesseract OCR reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "filtered_products = products_cleaned_first_ocr[products_cleaned_first_ocr['ingredient_list'].str.len() > 80]\n",
        "\n",
        "# Check if there are any products that meet the condition\n",
        "if not filtered_products.empty:\n",
        "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for filename in os.listdir(extracted_dir):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg') or filename.endswith('.webp'):\n",
        "            image_path = os.path.join(extracted_dir, filename)\n",
        "\n",
        "            try:\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is not None:\n",
        "                    # Use pytesseract.image_to_string to extract text\n",
        "                    result = pytesseract.image_to_string(image)\n",
        "                    results.append({'filename': filename, 'text': result})\n",
        "                else:\n",
        "                    print(f\"Failed to load image: {image_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {filename}: {str(e)}\")\n",
        "\n",
        "    # Create a DataFrame from the OCR results\n",
        "    df_pictures_tesseract = pd.DataFrame(results)\n",
        "    \n",
        "    # Merge the OCR results with the filtered_products DataFrame\n",
        "    df_pictures_tesseract = pd.merge(filtered_products, df_pictures_tesseract, how='inner', left_on='product_name', right_on='filename')\n",
        "else:\n",
        "    # If there are no products that meet the condition, create an empty DataFrame\n",
        "    df_pictures_tesseract = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preform cleaning after feading the files with Tesseract OCR reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def perform_second_ocr_cleaning(products):\n",
        "\n",
        "        products['full_ingredient_list'] = products['text_from_ocr']\n",
        "        products['full_ingredient_list'] = products['full_ingredient_list'].apply(lambda x: x.split('\\n'))          # Split each paragraph into a list\n",
        "        products['full_ingredient_list'] = products['full_ingredient_list'].apply(lambda x: [paragraph.strip() for paragraph in x if paragraph.strip()])    # Remove empty paragraphs if any\n",
        "        products['full_ingredient_list'] = products['full_ingredient_list'].apply(lambda x: ' '.join(map(str, x)))\n",
        "        products['ingredient_list'] = products['full_ingredient_list']                                              # Making unicode transliteration, lower case and tokenization\n",
        "\n",
        "        split_characters = [',', '|', '*', '«', '»', '-', ':', '+']        \n",
        "        for char in split_characters:\n",
        "            products['ingredient_list'] = products['ingredient_list'].apply(lambda x: ', '.join(x.split(char)))     # Iterate over each split character and perform the split [',', '|', '*', '«', '»', '-', ':', '+'] \n",
        "        products.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        products['ingredient_list'] = products['ingredient_list'].apply(clean_text)\n",
        "        products['ingredient_list'] = products['ingredient_list'].apply(lambda x: x.split(','))\n",
        "        products['ingredient_list'] = products['ingredient_list'].tolist()        \n",
        "        products['ingredient_list'] = products['ingredient_list'].apply(clean_text_before_ingredients)              # Apply the cleaning function\n",
        "        products = products.explode('ingredient_list')        \n",
        "        products['ingredient_list'] = products['ingredient_list'].apply(remove_unclosed_brackets)\n",
        "        products['ingredient_list'] = products['ingredient_list'].astype(str)\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace('[', '(').str.replace(']', ')')       # zamena na aglesti zagradi so obicni\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace('\\\\', '/')                            # zamena na \\ so /\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.lstrip(',')                                   # brisenje na ',' ako stringot pocnuva so ','\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace(' ,', ', ')                           # zamena na ' ,' so ', '\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.lstrip('/')                                   # brisenje / na pocetok na string\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.rstrip(string.punctuation.replace(')', ''))   # brisenje punktuacija na kraj na sting, no bez zagradite\n",
        "\n",
        "        special_characters = ['*', '$', '?', '!', '@', '}', '{', '_', '--', '>', '<', '~', '&', '=', '\"']\n",
        "        for char in special_characters:\n",
        "            products['ingredient_list'] = products['ingredient_list'].astype(str).str.replace(char, ' ')            # brisenje na specijalnite znaci bilo kade vo stringot\n",
        "        \n",
        "        products['ingredient_list'] = products['ingredient_list'].replace(r',+', ',', regex=True)                   # brisenje na povekje od 1 posledovatelni zapirki\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.strip().str.replace(r'\\s+', ' ')              # brisenje na povekje od 1 posledovatelni prazni mesta\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\s*/\\s*', '/')                      # brisenje na prazni mesta pred i posle '/'\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\s*-\\s*', '-')                      # brisenje na prazni mesta pred i posle '-'\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\s+\\.', '.')                        # brisenje na prazno mesto pred '.'\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\(\\s*', '(').str.replace(r'\\s*\\)', ')') # brisenje na prazni mesta posle otvorena zagrada i pred zatvorena zagrada\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace('f,i,l,', 'fil')\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.strip()                                       # trim\n",
        "        products = products[~products['ingredient_list'].astype(str).str.match(r'^[\\d\\W]+$')]                       # brisenje na red koj sodrzi samo broj i punktuacija\n",
        "        products = products[~products['ingredient_list'].str.strip(string.punctuation).eq('')]                      # brisenje na red koj sodrzi samo punktuacija\n",
        "        products = products[~products['ingredient_list'].apply(lambda x: pd.to_numeric(x, errors='coerce')).notna() | (products['ingredient_list'] == '')]  # samo broj\n",
        "        mask_to_drop = (products['ingredient_list'].str.len() < 3) | (products['ingredient_list'].str.len() > 80)   # Brisenje na red koj sodrzi pomalku od 3 ili povekje od 70 karakteri \n",
        "        products = products[~mask_to_drop]\n",
        "        products['ingredient_list'] = products['ingredient_list'].str.strip()   \n",
        "        products['ingredient_list'] = products['ingredient_list'].str.replace(r'\\s+', ' ', regex=True)              # Brisenje na prazni stringovi i NaN\n",
        "        products.dropna(subset=['ingredient_list'], inplace=True)\n",
        "        products.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        return products\n",
        "\n",
        "\n",
        "products2 = df_pictures_tesseract.copy()\n",
        "columns_to_drop = ['product_name', 'text_from_ocr', 'full_ingredient_list', 'ingredient_list']                      # Columns to drop from first ocr read\n",
        "products2.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
        "products2.rename(columns={'text': 'text_from_ocr'}, inplace=True)                                                   # Renaming the columns \n",
        "products2.rename(columns={'filename': 'product_name'}, inplace=True)\n",
        "\n",
        "products_cleaned_second_ocr = perform_second_ocr_cleaning(products2)                                                # Call the function to perform the cleaning   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_to_drop = products_cleaned_first_ocr['ingredient_list'].str.len() > 80                                                 # Brisenje na redovite koi sodrzat povekje od 80 karakteri\n",
        "products_to_drop = products_cleaned_first_ocr.loc[mask_to_drop, 'product_name'].unique()                                    # Identify the product names for which the condition is met\n",
        "products_cleaned_first_ocr = products_cleaned_first_ocr[~products_cleaned_first_ocr['product_name'].isin(products_to_drop)] # # Brisenje na recordite od products_cleaned_first_ocr, bidejki se vcituvaat od drugata biblioteka\n",
        "products_cleaned_first_ocr.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Concatanating dataframes from both readers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "products = pd.concat([products_cleaned_first_ocr, products_cleaned_second_ocr], axis=0)                             # Concatenate the two DataFrames along the columns\n",
        "products = products.sort_values(by='product_name')\n",
        "\n",
        "products['text_from_ocr'] = products['text_from_ocr'].apply(tuple)                                                  # Brisenje duplikati\n",
        "products.drop_duplicates(inplace=True)\n",
        "products.reset_index(drop=True, inplace=True)\n",
        "\n",
        "products['productID'] = products.groupby('product_name').ngroup()                                                   # Dodavanje index colona za sekoj proizvod\n",
        "products.insert(0, 'productID', products.pop('productID'))                                                          # Move 'productID' to the first column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "products_cleaned_first_ocr.to_excel('first_ocr_CleanDataset.xlsx')\n",
        "products_cleaned_second_ocr.to_excel('second_ocr_CleanDataset.xlsx')\n",
        "products.to_excel('ocr_CleanDataset.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>productID</th>\n",
              "      <th>product_name</th>\n",
              "      <th>text_from_ocr</th>\n",
              "      <th>full_ingredient_list</th>\n",
              "      <th>ingredient_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>20231204_141323.jpg</td>\n",
              "      <td>(_, -,  , -,  , -,  , O, e,  , n, m, ,, \\n, n,...</td>\n",
              "      <td>_- - - Oe nm, niccoli lontano dalla luce diret...</td>\n",
              "      <td>aqua</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>20231204_141323.jpg</td>\n",
              "      <td>(_, -,  , -,  , -,  , O, e,  , n, m, ,, \\n, n,...</td>\n",
              "      <td>_- - - Oe nm, niccoli lontano dalla luce diret...</td>\n",
              "      <td>glycerin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>20231204_141323.jpg</td>\n",
              "      <td>(_, -,  , -,  , -,  , O, e,  , n, m, ,, \\n, n,...</td>\n",
              "      <td>_- - - Oe nm, niccoli lontano dalla luce diret...</td>\n",
              "      <td>alcohol denat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>20231204_141323.jpg</td>\n",
              "      <td>(_, -,  , -,  , -,  , O, e,  , n, m, ,, \\n, n,...</td>\n",
              "      <td>_- - - Oe nm, niccoli lontano dalla luce diret...</td>\n",
              "      <td>homosalate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>20231204_141948.jpg</td>\n",
              "      <td>(Munaio, IAUNOTHUNI, DRLARAdU, GONDItIONg , co...</td>\n",
              "      <td>Munaio IAUNOTHUNI DRLARAdU GONDItIONg  contROl...</td>\n",
              "      <td>b02000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1908</th>\n",
              "      <td>99</td>\n",
              "      <td>f1bedfc1-c1ad-47ce-9618-710d7cbcb2b5.jpg</td>\n",
              "      <td>(I, N, G, R, E, D, I, E, N, T, S, /, I, N, G, ...</td>\n",
              "      <td>INGREDIENTS/INGREDIENTES/COCTAB (ING): AQUA/WA...</td>\n",
              "      <td>60 hydrogenated castor ou</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1909</th>\n",
              "      <td>99</td>\n",
              "      <td>f1bedfc1-c1ad-47ce-9618-710d7cbcb2b5.jpg</td>\n",
              "      <td>(I, N, G, R, E, D, I, E, N, T, S, /, I, N, G, ...</td>\n",
              "      <td>INGREDIENTS/INGREDIENTES/COCTAB (ING): AQUA/WA...</td>\n",
              "      <td>lauryl glucos peg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1910</th>\n",
              "      <td>99</td>\n",
              "      <td>f1bedfc1-c1ad-47ce-9618-710d7cbcb2b5.jpg</td>\n",
              "      <td>(I, N, G, R, E, D, I, E, N, T, S, /, I, N, G, ...</td>\n",
              "      <td>INGREDIENTS/INGREDIENTES/COCTAB (ING): AQUA/WA...</td>\n",
              "      <td>laurylalcohol diphosphonic acid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1911</th>\n",
              "      <td>99</td>\n",
              "      <td>f1bedfc1-c1ad-47ce-9618-710d7cbcb2b5.jpg</td>\n",
              "      <td>(I, N, G, R, E, D, I, E, N, T, S, /, I, N, G, ...</td>\n",
              "      <td>INGREDIENTS/INGREDIENTES/COCTAB (ING): AQUA/WA...</td>\n",
              "      <td>copper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1912</th>\n",
              "      <td>99</td>\n",
              "      <td>f1bedfc1-c1ad-47ce-9618-710d7cbcb2b5.jpg</td>\n",
              "      <td>(I, N, G, R, E, D, I, E, N, T, S, /, I, N, G, ...</td>\n",
              "      <td>INGREDIENTS/INGREDIENTES/COCTAB (ING): AQUA/WA...</td>\n",
              "      <td>hydroxyethylcellulose lauricacid</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1913 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      productID                              product_name  \\\n",
              "0             0                       20231204_141323.jpg   \n",
              "1             0                       20231204_141323.jpg   \n",
              "2             0                       20231204_141323.jpg   \n",
              "3             0                       20231204_141323.jpg   \n",
              "4             1                       20231204_141948.jpg   \n",
              "...         ...                                       ...   \n",
              "1908         99  f1bedfc1-c1ad-47ce-9618-710d7cbcb2b5.jpg   \n",
              "1909         99  f1bedfc1-c1ad-47ce-9618-710d7cbcb2b5.jpg   \n",
              "1910         99  f1bedfc1-c1ad-47ce-9618-710d7cbcb2b5.jpg   \n",
              "1911         99  f1bedfc1-c1ad-47ce-9618-710d7cbcb2b5.jpg   \n",
              "1912         99  f1bedfc1-c1ad-47ce-9618-710d7cbcb2b5.jpg   \n",
              "\n",
              "                                          text_from_ocr  \\\n",
              "0     (_, -,  , -,  , -,  , O, e,  , n, m, ,, \\n, n,...   \n",
              "1     (_, -,  , -,  , -,  , O, e,  , n, m, ,, \\n, n,...   \n",
              "2     (_, -,  , -,  , -,  , O, e,  , n, m, ,, \\n, n,...   \n",
              "3     (_, -,  , -,  , -,  , O, e,  , n, m, ,, \\n, n,...   \n",
              "4     (Munaio, IAUNOTHUNI, DRLARAdU, GONDItIONg , co...   \n",
              "...                                                 ...   \n",
              "1908  (I, N, G, R, E, D, I, E, N, T, S, /, I, N, G, ...   \n",
              "1909  (I, N, G, R, E, D, I, E, N, T, S, /, I, N, G, ...   \n",
              "1910  (I, N, G, R, E, D, I, E, N, T, S, /, I, N, G, ...   \n",
              "1911  (I, N, G, R, E, D, I, E, N, T, S, /, I, N, G, ...   \n",
              "1912  (I, N, G, R, E, D, I, E, N, T, S, /, I, N, G, ...   \n",
              "\n",
              "                                   full_ingredient_list  \\\n",
              "0     _- - - Oe nm, niccoli lontano dalla luce diret...   \n",
              "1     _- - - Oe nm, niccoli lontano dalla luce diret...   \n",
              "2     _- - - Oe nm, niccoli lontano dalla luce diret...   \n",
              "3     _- - - Oe nm, niccoli lontano dalla luce diret...   \n",
              "4     Munaio IAUNOTHUNI DRLARAdU GONDItIONg  contROl...   \n",
              "...                                                 ...   \n",
              "1908  INGREDIENTS/INGREDIENTES/COCTAB (ING): AQUA/WA...   \n",
              "1909  INGREDIENTS/INGREDIENTES/COCTAB (ING): AQUA/WA...   \n",
              "1910  INGREDIENTS/INGREDIENTES/COCTAB (ING): AQUA/WA...   \n",
              "1911  INGREDIENTS/INGREDIENTES/COCTAB (ING): AQUA/WA...   \n",
              "1912  INGREDIENTS/INGREDIENTES/COCTAB (ING): AQUA/WA...   \n",
              "\n",
              "                       ingredient_list  \n",
              "0                                 aqua  \n",
              "1                             glycerin  \n",
              "2                        alcohol denat  \n",
              "3                           homosalate  \n",
              "4                               b02000  \n",
              "...                                ...  \n",
              "1908         60 hydrogenated castor ou  \n",
              "1909                 lauryl glucos peg  \n",
              "1910   laurylalcohol diphosphonic acid  \n",
              "1911                            copper  \n",
              "1912  hydroxyethylcellulose lauricacid  \n",
              "\n",
              "[1913 rows x 5 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "products.drop_duplicates(inplace=True) \n",
        "products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of NaN values in 'ingredient_list': 0\n"
          ]
        }
      ],
      "source": [
        "nan_count = products['ingredient_list'].isna().sum()\n",
        "print(\"Number of NaN values in 'ingredient_list':\", nan_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "products = products[~products['ingredient_list'].eq('nan')]\n",
        "nan_rows = products['ingredient_list'].isna()\n",
        "print(nan_rows.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Converting to list\n",
        "ingredient_names = products['ingredient_list'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Jaccard distance Matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_first_match(ingredient, candidates, threshold=0.49):\n",
        "    ingredient_set = set(re.split(r'\\W+', ingredient))\n",
        "\n",
        "    # Set to keep track of matched ingredients\n",
        "    matched_ingredients = set()\n",
        "\n",
        "    for candidate in candidates:\n",
        "        # Skip if candidate ingredient has already been matched\n",
        "        if pd.notna(candidate):  # Check if candidate is not NaN\n",
        "            if candidate in matched_ingredients:\n",
        "                continue\n",
        "\n",
        "            if isinstance(candidate, str):  # Check if candidate is a string\n",
        "                candidate_set = set(re.split(r'\\W+', candidate))\n",
        "                union_size = len(ingredient_set.union(candidate_set))\n",
        "\n",
        "                if union_size != 0:\n",
        "                    distance = jaccard_distance(ingredient_set, candidate_set)\n",
        "                    similarity = 1 - distance\n",
        "\n",
        "                    if similarity > threshold:\n",
        "                        # Add the matched ingredient to the set\n",
        "                        matched_ingredients.add(candidate)\n",
        "                        \n",
        "                        # Return the first match and exit the function\n",
        "                        return candidate\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "matches_df = pd.DataFrame(columns=['Matching Ingredient', 'Synonym'])\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for ingredient in ingredient_names:\n",
        "    if isinstance(ingredient, str):\n",
        "        direct_match = [synonym for synonym in synonyms if synonym == ingredient] or [None]\n",
        "\n",
        "        if direct_match[0] == None:\n",
        "            match = find_first_match(ingredient, synonyms)\n",
        "        else:\n",
        "            match = direct_match[0]\n",
        "\n",
        "        df = pd.DataFrame({'Matching Ingredient': [ingredient], 'Synonym': [match]})\n",
        "\n",
        "        dfs.append(df)\n",
        "\n",
        "matches_df = pd.concat(dfs, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "synonym_to_generic = dict(zip(ingredients['synonym'], ingredients['generic_name']))\n",
        "\n",
        "# Add a new column to matches_df to store the corresponding generic name\n",
        "matches_df['Generic Name'] = None\n",
        "\n",
        "# Loop through each ingredient\n",
        "for index, row in matches_df.iterrows():\n",
        "    ingredient = row['Matching Ingredient']\n",
        "    match = row['Synonym']\n",
        "\n",
        "    # Check if the match is not None\n",
        "    if match is not None:\n",
        "        # Use the dictionary to find the corresponding generic name\n",
        "        generic_name = synonym_to_generic.get(match)\n",
        "\n",
        "        # Update the 'Generic_Name' column in matches_df\n",
        "        matches_df.at[index, 'Generic Name'] = generic_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MATCHED ingredients:               82.02 % \t/ 1569\n",
            "NOT MATCHED ingredients:           17.98 % \t/ 344\n",
            "\n",
            "EXACT MATCH of ingredients:        64.0 %\n",
            "JACCARD DISTANCE MATCH of ing.:    18.02 %\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Matching Ingredient</th>\n",
              "      <th>Synonym</th>\n",
              "      <th>Generic Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aqua</td>\n",
              "      <td>aqua</td>\n",
              "      <td>Water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>glycerin</td>\n",
              "      <td>glycerin</td>\n",
              "      <td>Glycerin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>alcohol denat</td>\n",
              "      <td>alcohol</td>\n",
              "      <td>Alcohol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>homosalate</td>\n",
              "      <td>homosalate</td>\n",
              "      <td>Homosalate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b02000</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1908</th>\n",
              "      <td>60 hydrogenated castor ou</td>\n",
              "      <td>peg-60 hydrogenated castor oil</td>\n",
              "      <td>Peg-60 Hydrogenated Castor Oil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1909</th>\n",
              "      <td>lauryl glucos peg</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1910</th>\n",
              "      <td>laurylalcohol diphosphonic acid</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1911</th>\n",
              "      <td>copper</td>\n",
              "      <td>copper acetylmethionate</td>\n",
              "      <td>Copper Acetylmethionate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1912</th>\n",
              "      <td>hydroxyethylcellulose lauricacid</td>\n",
              "      <td>hydroxyethylcellulose</td>\n",
              "      <td>Hydroxyethylcellulose</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1913 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Matching Ingredient                         Synonym  \\\n",
              "0                                 aqua                            aqua   \n",
              "1                             glycerin                        glycerin   \n",
              "2                        alcohol denat                         alcohol   \n",
              "3                           homosalate                      homosalate   \n",
              "4                               b02000                            None   \n",
              "...                                ...                             ...   \n",
              "1908         60 hydrogenated castor ou  peg-60 hydrogenated castor oil   \n",
              "1909                 lauryl glucos peg                            None   \n",
              "1910   laurylalcohol diphosphonic acid                            None   \n",
              "1911                            copper         copper acetylmethionate   \n",
              "1912  hydroxyethylcellulose lauricacid           hydroxyethylcellulose   \n",
              "\n",
              "                        Generic Name  \n",
              "0                              Water  \n",
              "1                           Glycerin  \n",
              "2                            Alcohol  \n",
              "3                         Homosalate  \n",
              "4                               None  \n",
              "...                              ...  \n",
              "1908  Peg-60 Hydrogenated Castor Oil  \n",
              "1909                            None  \n",
              "1910                            None  \n",
              "1911         Copper Acetylmethionate  \n",
              "1912           Hydroxyethylcellulose  \n",
              "\n",
              "[1913 rows x 3 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "none_count = 0\n",
        "for value in matches_df['Synonym']:\n",
        "    if str(value).strip().lower() == 'none':\n",
        "        none_count += 1\n",
        "\n",
        "matched = round((len(products) - none_count)/len(products), 4)*100\n",
        "not_matched = round((100-matched), 4)\n",
        "exact_matches = products['ingredient_list'][products['ingredient_list'].isin(ingredients['synonym'].values)].tolist()\n",
        "exact_matches = round(len(exact_matches)/len(products['ingredient_list']), 2)*100\n",
        "\n",
        "print(f'MATCHED ingredients:               {round(matched, 2)} % \\t/ {len(ingredient_names) - none_count}')\n",
        "print(f'NOT MATCHED ingredients:           {not_matched} % \\t/ {none_count}')\n",
        "print()\n",
        "print(f'EXACT MATCH of ingredients:        {exact_matches} %')\n",
        "print(f'JACCARD DISTANCE MATCH of ing.:    {round(matched-exact_matches, 2)} %')\n",
        "\n",
        "matches_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "matches_df[['Generic Name', 'Synonym', 'Matching Ingredient']].to_excel('matches_ocr_0.50_CleanDataset.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value: nan, Frequency: 5\n",
            "Value: cl 19140, Frequency: 3\n",
            "Value: c12, Frequency: 3\n",
            "Value: pentaerythrityl tetra, Frequency: 3\n",
            "Value: tocophery acetate, Frequency: 2\n",
            "Value: cl 77891, Frequency: 2\n",
            "Value: cetearylalcohol, Frequency: 2\n",
            "Value: cl 77492, Frequency: 2\n",
            "Value: cerin, Frequency: 2\n",
            "Value: gly, Frequency: 2\n",
            "Value: aquo, Frequency: 2\n",
            "Value: caprylic/capric trigly-ceride, Frequency: 2\n",
            "Value: lsomethy lonone, Frequency: 2\n",
            "Value: ethylhexyiglycerin, Frequency: 2\n",
            "Value: porfum, Frequency: 2\n",
            "Value: cl 14700, Frequency: 2\n",
            "Value: nonapep tide-1, Frequency: 1\n",
            "Value: xantha ca #, Frequency: 1\n",
            "Value: hexyl stearate, Frequency: 1\n",
            "Value: bru yy oh en panthenol chondr js cris parfum, Frequency: 1\n",
            "Value: hydroxy oxyethanol, Frequency: 1\n",
            "Value: uinalo fee ate, Frequency: 1\n",
            "Value: oryza, Frequency: 1\n",
            "Value: bht: 6 8 8 cneg aqua, Frequency: 1\n",
            "Value: gera, Frequency: 1\n",
            "Value: niol, Frequency: 1\n",
            "Value: xant, Frequency: 1\n",
            "Value: han gum, Frequency: 1\n",
            "Value: tract, Frequency: 1\n",
            "Value: y sulfate, Frequency: 1\n"
          ]
        }
      ],
      "source": [
        "# Analysis of unmatched ingredients\n",
        "filtered_df = matches_df[matches_df['Generic Name'].isna()]\n",
        "value_counts = filtered_df['Matching Ingredient'].value_counts()\n",
        "\n",
        "# Print the first 20 most frequent values and their frequencies\n",
        "for value, frequency in value_counts.head(30).iteritems():\n",
        "    print(f\"Value: {value}, Frequency: {frequency}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# products_aggregated = products.groupby('productID')['ingredient_list'].agg(list).reset_index()\n",
        "# products_aggregated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# products_aggregated.to_excel('products_aggregated_NewPictures.xlsx')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
